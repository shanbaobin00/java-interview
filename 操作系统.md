## 一、操作系统基础

### **1.1、什么是操作系统**

1.操作系统是管理计算机硬件与软件的程序；

2.操作系统本质上是运行再计算机上的软件；

3.操作系统为用户和应用程序提供接口；

4.操作系统分为内核和外壳（外壳就是围绕内核的应用程序）



内核负责管理系统的进程、内存、设备驱动程序、文件和网络系统等等，决定着系统的性能和稳定性。

内核是连接应用程序和硬件的桥梁。



### **1.2、什么是系统调用**

介绍系统调用前，我们先了解下用户态和内核态。

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1.用户态（user mode）：用户态运行的进程可以直接读取用户程序的数据。

2.内核态（kernel mode）：可以简单的理解内核态运行的进程几乎可以访问计算机的任何资源，不受限制。

说了用户态和系统态之后，那么什么是系统调用呢？

我们运行的程序基本都是运行在用户态，如果我们想调用操作系统提供的内核态级别的子功能怎么办呢？那就需要系统调用了！

也就是说在我们运行的用户程序中，凡是与内核态级别的资源有关操作（如文件管理、进程控制、内存管理等），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

+ 设备管理。完成设备的请求或释放，以及设备启动等功能。
+ 文件管理。完成文件的读、写、创建及删除等功能。
+ 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
+ 进程通信。完成进程之间的消息传递或信号传递等功能。
+ 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。



## 二、进程和线程



### **2.1、进程和线程的区别** 

​		**进程：**是资源分配的最小单位，是程序的执行过程，一个进程可以有多个线程，多个线程共享进程的堆和方法区资源，但每个线程又有属于自己的本地方法栈、虚拟机栈、程序计数器

​		**线程：**是任务调度和执行的最小单位，线程间可能存在相互影响，执行开销较小，不利于资源的管理和保护，线程间是共享进程中的资源的



### **2.2、协程？** 

​		是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。



### **2.3、进程间通信方式IPC** 

参考：https://www.jianshu.com/p/c1015f5ffa74

**匿名管道pipe：**

​		匿名管道是半双工的，数据只能单向通信；需要双方通信时，需要建立起两个管道；只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）。

**命名管道FIFO：**

​		不同于匿名管道之处在于它提供一个路径名与之关联，以FIFO的文件形式存在于文件系统中。这样，即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过FIFO相互通信（能够访问该路径的进程以及FIFO的创建进程之间），因此，通过FIFO不相关的进程也能交换数据。值得注意的是，FIFO严格遵循先进先出（first in first out），对管道及FIFO的读总是从开始处返回数据，对它们的写则把数据添加到末尾。

**信号：**

​		信号是一种比较复杂的通信方式，信号产生的条件：按键、硬件异常、进程调用kill函数将信号发送给另一个进程、用户调用kill命令将信号发送给其他进程，信号传递的消息比较少，主要用于通知接收进程某个时间已经发生。

**消息队列：**

​		消息队列是消息的链表，存放在内核中并由消息队列标识符标识，消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点。消息队列起信箱作用，到了就挂在那里，需要的时候去取。消息队列提供了一种在两个不相关进程间传递数据的简单有效的方法。与命名管道相比：消息队列的优势在于，它独立于发送和接收进程而存在，这消除了在同步命名管道的打开和关闭时可能产生的一些困难。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。而且，每个数据块被认为含有一个类型，接收进程可以独立地接收含有不同类型值的数据块。

​	**优点：**

​		A. 我们可以通过发送消息来几乎完全避免命名管道的同步和阻塞问题。

​		B. 我们可以用一些方法来提前查看紧急消息。

​	**缺点：**

​		A. 与管道一样，每个数据块有一个最大长度的限制。

​		B. 系统中所有队列所包含的全部数据块的总长度也有一个上限。

**共享内存(share memory)：**

- 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。
- 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
- 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

**信号量(Semaphores) ：**

​		信号量是⼀个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。

**套接字(Sockets) :** 

​		此⽅法主要⽤于在客户端和服务器之间通过⽹络进⾏通信。套接字是⽀持TCP/IP 的⽹络通信的基本操作单元，可以看做是不同主机之间的进程进⾏双向通信的端点，简单的说就是通信的两⽅的⼀种约定，⽤套接字中的相关函数来完成通信过程。



### **2.4、用户态和核心态** 

​	在计算机系统中，分两种程序：系统程序和应用程序，为了保证系统程序不被应用程序有意或无意地破坏，为计算机设置了两种状态——用户态、核心态

**用户态：**只能受限的访问内存，运行所有的应用程序

**核心态：**运行操作系统程序，cpu可以访问内存的所有数据，包括外围设备

**为什么要有用户态和内核态：**

​		由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络

**用户态切换到内核态的3种方式：**

​	**a. 系统调用**

​		这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

​	**b. 异常**

​		当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

​	**c. 外围设备的中断**

​		当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

​		这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

​	

### **2.5、线程间的同步的方式**

​	1、互斥量(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如Java中的synchronized关键字和各种Lock都是这种机制。

​	2、信号量(Semphares)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。

​	3、事件(Event)：Wait/Notify：通过通知操作的方式来保持多线程同步。



### **2.6、操作系统分配的进程空间是怎样的？线程能共享哪些？** 

​	栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。

​	堆区（heap）— 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。

​	静态区（static）—存放全局变量和静态变量的存储

​	代码区(text)—存放函数体的二进制代码。

​	**线程共享堆区、静态区**



### **2.7、进程的调度算法**

​	**先到先服务(FCFS)调度算法**：从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用CPU时再重新调度。

​	**短作业优先(SJF)调度算法**：从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用CPU时再重新调度。

​	**时间片轮转调用算法**：时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。

​	**多级反馈队列调度算法**：前面介绍的几种进程调度的算法都有一定的局限性。如**短作业优先的调度算法，仅照顾了短进程而忽略了长进程**。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前**被公认的一种较好的进程调度算法**，UNIX操作系统采取的便是这种调度算法。

​	**优先级调度**：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以FCFS方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。



### **2.8、死锁条件，解决方式。** 

​	死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待的现象；

​	**死锁的条件：**

​		互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；

​		请求与保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源

​		非剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放

​		循环等待条件：系统中若干进程组成环路，环路中每个进程都在等待相邻进程占用的资源

​	**解决方法：**破坏死锁的任意一条件

​		资源一次性分配，从而剥夺请求和保持条件

​		可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件

​		资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件



## 三、操作系统内存管理基础



### **3.1、内存管理主要做什么**

​	操作系统的内存管理主要负责内存的分配与回收，另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。



### **3.2、操作系统内存管理方式，分页分段以及段页式的优缺点** 

参考地址：https://blog.csdn.net/qq_37189082/article/details/97963763

**存管理方式：**块式管理、页式管理、段式管理、段页式管理

**块式管理：**

​		远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些再每个块中未被利用的空间，我们称之为碎片。

**段式管理：**

​		在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

**页式管理：**

​		在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）

**段页式管理：**

​		段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制 中段与段之间以及段的内部的都是离散的。

**分页和分段有什区别？**

- 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 
- 分页的地址空间是一维地址空间，分段是二维的。 
- 页的大小不可变，段的大小可以动态改变。 
- 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 



### 3.3、快表和多级页表，分别解决了什么问题？

​	在分页内存管理中，很重要的两点是：

​	1.虚拟地址到物理地址的转换要快。

​	2.解决虚拟地址空间大，页表也会很大的问题。

**快表**：

​	解决虚拟地址到物理地址的转换速度，操作系统在**页表方案**基础之上引入了**快表**来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器(Cache)，其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读取内存数据时CPU要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

**多级页表**：

​	引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。

总结：

​	为了提高内存的空间性能，提出了多级页表的概念；但是提高空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即TLB）的概念。不论是快表还是多级页表实际上都利用了程序的局部性原理，局部性原理参考虚拟内存这部分。



### 3.4、分页机制和分段机制的共同点和区别

共同点：

+ 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
+ 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

区别：

+ 页的大小是固定的，有操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
+ 分页仅仅是为了满足操作系统的内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。



### 3.5逻辑(虚拟)地址和物理地址

​	我们编程一般只可能和逻辑地址打交道，比如C语言中的指针或者java语言的引用，就可以理解为内存的一个地址，这个地址就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中的地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。



### 3.6、CPU寻址了解吗？为什么需要虚拟地址空间？

​	现代处理器使用的是一种称为**虚拟地址**（**Virtual Addressing**）的寻址方式。使用虚拟地址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。实际上完成虚拟地址转换为物理地址的硬件是CPU中含有一个被称为**内存管理单元**（Memory Management Unit，MMU）的硬件。

**为什么要有虚拟地址空间呢？**

​	先从没有虚拟地址空间的时候说起吧！**没有虚拟地址空间的时候，程序直接访问和操作的都是物理内存**。但是这样由什么问题呢？

​	1.用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。

​	2.想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个QQ音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址1XXX赋值后，QQ音乐也同样给内存地址1XXX赋值，那么QQ音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话就会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难**。

通过虚拟地址访问内存有以下优势：

+ 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
+ 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为4KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
+ 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更正正在由另一进程或操作系统使用的物理内存。



### **3.7、页面置换算法有哪些，FIFO为什么不好？如何改进?LRU思想，手写LRU** 

**置换算法：**先进先出FIFO、最近最久未使用LRU、最佳置换算法OPT

**先进先出FIFO:**

​		原理：把内存中驻留时间最久的页面置换算法予以淘汰

​		优点：实现简单、直观

​		缺点：没有考虑到实际的页面使用频率，性能差、与通常页面使用的规则不符合，实际应用较少

​		改进：给每个页面增加一个R位，每次先从链表头开始查找，如果R置位，清除R位并且把该页面节点放	到链表结尾；如果R是0，那么就是又老又没用到，替换掉。

**最近最久未使用LRU:**

​		原理：选择最近且最久未使用的页面进行淘汰

​		优点：考虑到了程序访问的时间局部性，有较好的性能，实际应用也比较多

​		缺点：实现需要比较多的硬件支持，会增加一些硬件成本

​		手写LRU: 参考 https://www.jianshu.com/p/ec1952b9d84a

```java
/**
 * @program: Java
 * @description: LRU最近最久未使用置换算法，通过LinkedHashMap实现
 * @author: Mr.Li
 * @create: 2020-07-17 10:29
 **/
public class LRUCache {
    private LinkedHashMap<Integer,Integer> cache;
    private int capacity;   //容量大小

    /**
     *初始化构造函数
     * @param capacity
     */
    public LRUCache(int capacity) {
        cache = new LinkedHashMap<>(capacity);
        this.capacity = capacity;
    }

    public int get(int key) {
        //缓存中不存在此key，直接返回
        if(!cache.containsKey(key)) {
            return -1;
        }

        int res = cache.get(key);
        cache.remove(key);   //先从链表中删除
        cache.put(key,res);  //再把该节点放到链表末尾处
        return res;
    }

    public void put(int key,int value) {
        if(cache.containsKey(key)) {
            cache.remove(key); //已经存在，在当前链表移除
        }
        if(capacity == cache.size()) {
            //cache已满，删除链表头位置
            Set<Integer> keySet = cache.keySet();
            Iterator<Integer> iterator = keySet.iterator();
            cache.remove(iterator.next());
        }
        cache.put(key,value);  //插入到链表末尾
    }
}

```

```java
/**
 * @program: Java
 * @description: LRU最近最久未使用置换算法，通过LinkedHashMap内部removeEldestEntry方法实现
 * @author: Mr.Li
 * @create: 2020-07-17 10:59
 **/
class LRUCache {
    private Map<Integer, Integer> map;
    private int capacity;
	
    /**
     *初始化构造函数
     * @param capacity
     */
    public LRUCache(int capacity) {
        this.capacity = capacity;
        map = new LinkedHashMap<Integer, Integer>(capacity, 0.75f, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry eldest) {
                return size() > capacity;  // 容量大于capacity 时就删除
            }
        };
    }
    public int get(int key) {
        //返回key对应的value值，若不存在，返回-1
        return map.getOrDefault(key, -1);
    }

    public void put(int key, int value) {
        map.put(key, value);
    }
}
```

**最佳置换算法OPT:**

​		原理：每次选择当前物理块中的页面在未来长时间不被访问的或未来不再使用的页面进行淘汰

​		优点：具有较好的性能，可以保证获得最低的缺页率

​		缺点：过于理想化，但是实际上无法实现（没办法预知未来的页面）



## 四、虚拟内存



### 4.1、什么是虚拟内存（Virtual Memory）

有时电脑软件占用内存远远超出实际的物理内存大小，这是因为**虚拟内存**的存在。

+ 通过**虚拟内存**可以让程序可以拥有超过系统物理内存大小的可用内存空间。

+ 另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效管理内存并减少出错。



### 4.2、局部性原理

局部性原理是虚拟技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

​	1.**时间局部性**：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。

​	2.**空间局部性**：一旦程序访问了某个存储单元，在不久后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。



### 4.3、虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不适用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**。



### 4.4、虚拟内存的技术实现

虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现由以下三种方式：

​	1.**请求分页存储管理**：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分页即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。

​	2.**请求分段存储管理**：建立在分段管理之上，增加了请求调段功能、分段置换功能。请求分段存储管理方式就如同请求分页存储管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。

​	3.**请求段页式存储管理**：



### 4.5、页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断。

当发现缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

+ **OPT页面置换算法（最佳页面置换算法）**：最佳（Optimal，OPT）置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。

+ **FIFO（Fisrt In First Out）页面置换算法（先进先出页面置换算法）**：总是淘汰最先进入内存的页面，即选择再内存中驻留时间最久的页面进行淘汰。

+ **LRU（Least Currently Used）页面置换算法（最近最久未使用页面置换算法）**：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，当必须淘汰一个页面时，选择现有页面中其T值最大的，即最近最久未使用的页面予以淘汰。

+ **LFU（Least Frequently Used）页面置换算法（最少使用页面置换算法）**：该置换算法选择再之前时期使用最少的页面作为淘汰页。

+ **时钟算法**

  时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。它将整个环形链表的每一个页面做一个标记，如果标记是`0`，那么暂时就不会被替换，然后时钟算法遍历整个环，遇到标记为`1`的就替换，否则将标记为`0`的标记为`1`。



## 五、磁盘



### **5.1、有哪些磁盘调度算法？**

**先来先服务**

- 按照磁盘请求的顺序进行调度。 
- 优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 

**最短寻道时间优先**

- 优先调度与当前磁头所在磁道距离最近的磁道。 
- 虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。一般来说，两端的磁道请求更容易出现饥饿现象。 

**电梯算法**

- 也叫`SCAN`扫描算法。电梯算法就是说读写磁头总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。 
- 因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了最短寻道时间优先的饥饿问题。 



